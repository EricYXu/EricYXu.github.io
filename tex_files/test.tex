\documentclass[letterpaper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[left=0.2in,
            right=0.2in,
            top=0.2in,
            bottom=0.2in,footskip=0.25in]{geometry}

\pagestyle{empty}

\begin{document}

\section*{2013 Final}
\noindent
\textbf{Problem 1:} Try to employ Bayes' Rule or LOTP here. Also, the simplifying terms should arise when you try to divide the numerator and denominator by a convenient term (like $p_0$ on 2015 to get $a = p_1 / p_0$). Note when to use LOTP with extra conditioning (usually when you have additional info from another part). \textbf{ALWAYS CHECK IF THE SECOND PART WANTS YOU TO USE INFORMATION FROM THE FIRST PART!!!}

\noindent
\textbf{Problem 2:} (a) When you see a CDF or $P(X \geq k)$ when $X$ is non-negative, try to use Markov's Inequality. However, $X$ has a support that has negative and positive values, then you cannot use since it is possible that $E(X) < 0$ but $P(X \geq k)$ can never be negative by definition. (b) With iid random variables $X,Y,Z$, you can say that $[F_{X}(k)]^3 = P(X \leq k, Y \leq k, Z \leq k) \leq P(X+Y+Z \leq 3k)$. 

\noindent
\textbf{Problem 3:} (a,b,c) Recall again that indicators are good for finding expectation and variance. When taking the variance of a sum of indicator random variables, use the variance-covariance formula: $Var(I_1 + \ldots + I_n) = n \mbox{Var}(I_1) + (n)(n-1) \mbox{Covar}(I_1, I_2)$. Also recall multiplication rule does not care about ordering. 

\section*{2015 Final}
\noindent
\textbf{Problem 1:} (a,b) Remember to simplify your answers by conveniently dividing by a specific term (see what they want). Also note that when using LOTP with or without extra conditioning, try to see if the target is already known (e.g. in six-finger problem, the perpetrator is fixes so no need for binomial coeff.).

\noindent
\textbf{Problem 2:} (a) Look for symmetry via orderings. (b) You CANNOT use Markov's inequality on r.v $X$ to assess $P(X>1) \_\_\_ \; E(X)$, since it relies on absolute values and it is possible for $E(X) < 0$. Possible for $P(X \leq k) \geq E(|X|) / k$ if  (c) You can use Jensen's inequality with multiple random variables, just set a placeholder r.v and use linearity of expectation when finding the RHS of the inequality. (e) Recall if $X,Y$ are independent, then $\mbox{Var}(X|Y) = \mbox{Var}(X)$. Also note that $\mbox{Var}(X^2 | X) = 0$, because $X$ would be fixed. (f) Note that given iid $X,Y,Z$, then $\mbox{Var}(aX - bY - cZ) = a^2\mbox{Var}(X) + b^2 \mbox{Var}(Y) + c^2 \mbox{Var}(Z)$, since the negative goes inside the variance argument and then gets freakin squared bro. 

\noindent
\textbf{Problem 3:} (b) By the Chicken-Egg story, if you have $N \sim \mbox{Poisson}(\lambda)$, and some classification $A$ by probability $p$ and $B$ by probability $1-p$, then $N_A \sim \mbox{Poisson}(\lambda p), N_B \sim \mbox{Poisson}(\lambda (1-p))$ and $N_A$ and $N_B$ are \underline{independent}. Note though that $N_A | N = n \sim \mbox{Bin}(n, p)$. But $N_A | N_B = b \sim N_A$ since indep. Try Adam's Law and Eve's Law, and set a placeholder r.v for the sum of the individual things (with total count Poisson r.v).

\noindent
\textbf{Problem 4:} (b) Recall that the Principle of Inclusion-Exclusion is: $P(A_1 \cup \ldots \cup A_n) = \sum_{i=1}^{n} (-1)^{i+1} \dbinom{n}{i} P(A_1 \cap \ldots \cap A_i)$. (c) When using Poisson Approximations, $\lambda = \sum_{i}^{n} p_i$, where $p_i$ is the probability of the rare event $i$. 

\noindent
\textbf{Problem 6:} (a) 


\section*{2016 Final}
\noindent
\textbf{Problem 1:}

\noindent
\textbf{Problem 2:} (b) \underline{Did you check to use Markov's inequality or Jensen's inequality} for the problems regarding $P(X > n)$ or $E(g(X))$? Note the sign of RV. Also try to \underline{combine} iid r.v's, especially with Normal and Binomial. (c) For series questions, it is useful to first take the infinite case of the event on LHS (A) and \underline{see if it implies the event on the right} (B). If it does, then that means that $P(A) \leq P(B)$. However, you also need to check if the RHS event implies the LHS event (e.g. if $X$ is discrete RV, then event $X>2$ is the same as $X \geq 3$, and then plug in 3 to the LHS), which would mean $P(A) \geq P(B)$. In this case, then $P(A) = P(B)$. (d) Realize that if $I$ is an indicator r.v., then by LOTUS, \underline{$E(e^{I}) = pe + (1-p)$}. This means that if $X \sim \mbox{Bin}(n,p)$, then $E(e^{X}) = E(e^{I + \ldots + I}) = (pe + 1 - p)^n$. (e) When dealing with variances of Binomial r.v's, try to see if you can set an upper bound using \underline{derivative} test. (f) Note symmetry in the case of $E(X+Y|X+Y=n) = 2 E(X|X+Y=n) = n$.

\noindent
\textbf{Problem 3:}

\noindent
\textbf{Problem 4:} (b) When you divide a random variable into indicator r.v's, those \underline{indicators are NOT independent}. This is why you can only use linearity for expectation, but NOT variance. If you wanted variance, you would need to use variance-covariance formula. 

\noindent
\textbf{Problem 5:} (a) When comparing two independent Normal r.v's, you can combine them and then standardize to find the probability of some event. 


\noindent
\textbf{Problem 8:} (a) Use first-step analysis and condition on whether the first move goes to one state or another state. Then solve a system of equations to find each expectation value (remember to add by one for the step you already made). (b) If a Markov chain has a \underline{symmetric} transition matrix, then it has a \underline{uniform} stationary distribution across on all states. 

\section*{2017 Final}

\noindent
\textbf{Problem 2:} (f) WHENEVER YOU SEE $E(e^{N})$ where $N$ is a Normal random variable, use LogNormal!!!

\section*{2021 Final}

\noindent
\textbf{Problem 1:} If $A,C$ are conditionally independent given $B$, then $P(C|A,B) = P(C|B)$ since $A$ provides no information. Also, when doing LOTP with extra conditioning, see that: $P(C|A) = P(C|A,B) P(B|A) + P(C|A,B^c) P(B^c |A)$. 


\section*{2023 Final}
\noindent
\textbf{Problem 1:} BE SURE TO USE THE EVENTS/INFO in Part (a) in the subsequent parts!!!

\noindent
\textbf{Problem 2:} (c) You can relate the sum of two squares of Normal random variables to $\mbox{Gamma}(1,1/2)$, and then use the Memoryless property by splitting $5^2 = 3^2 + 4^2$. (d) Create a bivariate normal r.v with $(Z-W, Z+W)$, then note that if two things in valid multivariate normal have zero covariance, then they are independent. (e) Remember to use the GOSHDARN LogNormal Distribution when you have a linear combination of Normal random variables in the exponent of $e$. 

% \noindent
% \textbf{Problem 3:}
% \noindent
% \textbf{Problem 4:}
% \noindent
% \textbf{Problem 5:}
% \noindent
% \textbf{Problem 6:}
% \noindent
% \textbf{Problem 7:}
% \noindent
% \textbf{Problem 8:}

\section*{Extra Stuff Not Covered}
\textbf{Bayes' Billards:} $\int_{0}^{1} \dbinom{n}{k} x^k (1-x)^{n-k} \, dx = \dfrac{1}{n+1}$

\noindent
\textbf{Birth-Death Chain:} A Markov chain that involves each state only being able to transition to the left-state, right-state, or itself. A birth-death chain is always reversible, which implies that the chain has a stationary distribution. I believe you can set up a system of equations since $s_i q_{ij} = s_j q_{ji}$ for reversible chains. Then let $\sum_{i}^{n} s_i = 1$. 

\noindent
\textbf{Metropolis-Hastings Algorithm:} (1) Create an arbitrary Markov chain. (2) Propose to move from state $i$ to state $j$ with transition probability $q_{ij}$. (3) Compute acceptance probability of going to that state $a_{ij} = \min \left( 1, \dfrac{s_{j}q_{ji}}{s_{i}q_{ij}} \right)$, where $s_i,s_j$ are the stationary distribution probabilities (in this algorithm, the stationary probabilities are your target probabilities). (4) Flip a coin with probability heads equal to $a_{ij}$. (5) If heads, accept proposal. If tails, reject. FOR MOVING FROM STATE $i$ TO STATE $i$, YOU MUST ALSO ACCOUNT FOR THE FAILURE PROBABILITIES OF EVERY OTHER non-$i$ STATE. 

\noindent
\textbf{Change of Variables:} Sometimes, when the function you want to change your r.v to is too complex, you can first express your changed variable CDF as $P(g(X) \leq k)$, and then take the inverse on both sides to get an equivalent CDF $P(X \leq g^{-1}(k))$, if $g$ invertible. 

\noindent
\textbf{Extra Markov:} If you want to find the n-step transition matrix, just raise the transition matrix $Q$ to the $n$-th power. And in an irreducible Markov chain with finite state-space, all states are recurrent. 

\noindent
\textbf{Bank-Post Office:} If $X \sim \mbox{Gamma}(a,\lambda)$ and $Y \sim \mbox{Gamma}(b,\lambda)$, then $T = X+Y \sim \mbox{Gamma}(a+b,\lambda)$ and $W = \dfrac{X}{X+Y} \sim \mbox{Beta}(a,b)$. Also, $T$ is independent of $W$. 

\noindent
\textbf{Beta-Binomial Conjugacy:} Given a coin with an unknown probability of flipping heads, $X$ is number of heads, $p$ is unknown probability of heads. We want to infer distribution of $p$ given our flips. We see that $X|p \sim \mbox{Bin}(n,p)$, but if we let $p \sim \mbox{Beta}(1,1) = \mbox{Unif}(0,1)$, then we find: $p|X=k \sim \mbox{Beta}(a+k, b+n-k)$, where $n$ is total number of flips done.

\end{document}